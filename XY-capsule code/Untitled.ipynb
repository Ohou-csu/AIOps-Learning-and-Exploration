{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d42abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.io as sci\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import h5py\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243e03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk.classify.megam import numpy\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbe903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /Users/pro/Documents/Sklearn/venv/lib/python3.6/site-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/pro/Documents/Sklearn/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "!pip install torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547d5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b5a43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>-0.907673</td>\n",
       "      <td>1.168743</td>\n",
       "      <td>0.732893</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.578619</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064005</td>\n",
       "      <td>-1.017375</td>\n",
       "      <td>-0.965043</td>\n",
       "      <td>0.446558</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.437597</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>-1.675586</td>\n",
       "      <td>-1.365127</td>\n",
       "      <td>0.160224</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.617291</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>0.079644</td>\n",
       "      <td>1.168743</td>\n",
       "      <td>1.591895</td>\n",
       "      <td>-0.265008</td>\n",
       "      <td>0.862663</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.296572</td>\n",
       "      <td>0.189345</td>\n",
       "      <td>-1.098404</td>\n",
       "      <td>-0.126110</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-2.416853</td>\n",
       "      <td>-0.477236</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>1.615469</td>\n",
       "      <td>1.435466</td>\n",
       "      <td>0.446558</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.063482</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11196</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>1.615469</td>\n",
       "      <td>1.435466</td>\n",
       "      <td>0.732893</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.062816</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11197</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>1.615469</td>\n",
       "      <td>1.435466</td>\n",
       "      <td>1.019227</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.062816</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11198</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>1.615469</td>\n",
       "      <td>1.435466</td>\n",
       "      <td>1.305561</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.062482</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>1.615469</td>\n",
       "      <td>1.435466</td>\n",
       "      <td>1.591895</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.063149</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      1.168561 -0.907673  1.168743  0.732893 -0.307202  0.578619 -0.399994   \n",
       "1     -0.064005 -1.017375 -0.965043  0.446558 -0.307202  0.437597 -0.399994   \n",
       "2      1.168561 -1.675586 -1.365127  0.160224 -0.307202  0.617291 -0.399994   \n",
       "3      1.168561  0.079644  1.168743  1.591895 -0.265008  0.862663 -0.399994   \n",
       "4     -1.296572  0.189345 -1.098404 -0.126110 -0.349396 -2.416853 -0.477236   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11195  1.168561  1.615469  1.435466  0.446558 -0.349396 -0.063482 -0.399994   \n",
       "11196  1.168561  1.615469  1.435466  0.732893 -0.349396 -0.062816 -0.399994   \n",
       "11197  1.168561  1.615469  1.435466  1.019227 -0.349396 -0.062816 -0.399994   \n",
       "11198  1.168561  1.615469  1.435466  1.305561 -0.349396 -0.062482 -0.399994   \n",
       "11199  1.168561  1.615469  1.435466  1.591895 -0.349396 -0.063149 -0.399994   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          7  \n",
       "3         10  \n",
       "4          3  \n",
       "...      ...  \n",
       "11195     14  \n",
       "11196     14  \n",
       "11197     14  \n",
       "11198     14  \n",
       "11199     14  \n",
       "\n",
       "[11200 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('../capsule_code/data/nc_train_0.csv', sep=' ',header=None,names=['0','1','2','3','4','5','6','label'])\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad23f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.296572</td>\n",
       "      <td>-0.688269</td>\n",
       "      <td>-0.831681</td>\n",
       "      <td>-0.412444</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.306243</td>\n",
       "      <td>-0.361374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064005</td>\n",
       "      <td>-1.456182</td>\n",
       "      <td>-1.231766</td>\n",
       "      <td>-0.985112</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-2.416853</td>\n",
       "      <td>-0.477236</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>-0.578567</td>\n",
       "      <td>0.235212</td>\n",
       "      <td>-1.557780</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.491938</td>\n",
       "      <td>-0.361374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>-1.675586</td>\n",
       "      <td>-0.431596</td>\n",
       "      <td>-1.271446</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.627293</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>-1.675586</td>\n",
       "      <td>-1.098404</td>\n",
       "      <td>1.305561</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.618958</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>-1.296572</td>\n",
       "      <td>-0.030058</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>1.019227</td>\n",
       "      <td>-0.138425</td>\n",
       "      <td>0.339581</td>\n",
       "      <td>-0.245511</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>1.168561</td>\n",
       "      <td>0.847556</td>\n",
       "      <td>-1.231766</td>\n",
       "      <td>1.305561</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.057481</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>-1.296572</td>\n",
       "      <td>0.408749</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>-0.412444</td>\n",
       "      <td>-0.265008</td>\n",
       "      <td>0.355584</td>\n",
       "      <td>-0.322753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>-0.064005</td>\n",
       "      <td>1.286364</td>\n",
       "      <td>-0.698319</td>\n",
       "      <td>0.732893</td>\n",
       "      <td>-0.307202</td>\n",
       "      <td>0.539946</td>\n",
       "      <td>-0.399994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>-1.296572</td>\n",
       "      <td>-0.688269</td>\n",
       "      <td>1.435466</td>\n",
       "      <td>0.160224</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-2.416853</td>\n",
       "      <td>0.720012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -1.296572 -0.688269 -0.831681 -0.412444 -0.307202  0.306243 -0.361374   \n",
       "1    -0.064005 -1.456182 -1.231766 -0.985112 -0.349396 -2.416853 -0.477236   \n",
       "2     1.168561 -0.578567  0.235212 -1.557780 -0.307202  0.491938 -0.361374   \n",
       "3     1.168561 -1.675586 -0.431596 -1.271446 -0.307202  0.627293 -0.399994   \n",
       "4     1.168561 -1.675586 -1.098404  1.305561 -0.307202  0.618958 -0.399994   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2795 -1.296572 -0.030058  0.635296  1.019227 -0.138425  0.339581 -0.245511   \n",
       "2796  1.168561  0.847556 -1.231766  1.305561 -0.349396 -0.057481 -0.399994   \n",
       "2797 -1.296572  0.408749  0.635296 -0.412444 -0.265008  0.355584 -0.322753   \n",
       "2798 -0.064005  1.286364 -0.698319  0.732893 -0.307202  0.539946 -0.399994   \n",
       "2799 -1.296572 -0.688269  1.435466  0.160224 -0.349396 -2.416853  0.720012   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         3  \n",
       "2         0  \n",
       "3         7  \n",
       "4         7  \n",
       "...     ...  \n",
       "2795     12  \n",
       "2796     11  \n",
       "2797      0  \n",
       "2798      0  \n",
       "2799      5  \n",
       "\n",
       "[2800 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('../capsule_code/data/nc_test_0.csv', sep=' ',header=None,names=['0','1','2','3','4','5','6','label'])\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cad75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集\n",
    "train_set = shuffle(train_set)\n",
    "all_train_data = shuffle(train_set)\n",
    "train_data = all_train_data[['0','1','2','3','4','5','6']]\n",
    "train_label = all_train_data['label']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_label, test_size = 0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee0855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "test_set = shuffle(test_set)\n",
    "all_test_data = shuffle(test_set)\n",
    "X_test = all_test_data[['0','1','2','3','4','5','6']]\n",
    "y_test = all_test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854f3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid = np.array(X_train).reshape(-1, 7), np.array(X_test).reshape(-1, 7), np.array(X_valid).reshape(-1, 7)\n",
    "y_train, y_test, y_valid = np.array(y_train).reshape(-1, 1), np.array(y_test).reshape(-1, 1), np.array(y_valid).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25cdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train, X_valid, X_test = torch.FloatTensor(X_train), torch.FloatTensor(X_valid), torch.FloatTensor(X_test)\n",
    "y_train, y_valid, y_test = torch.FloatTensor(y_train), torch.FloatTensor(y_valid), torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794fc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(Dataset):\n",
    "  # 'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data, labels):\n",
    "        # 'Initialization'\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        # 'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 'Generates one sample of data'\n",
    "        # Select sample\n",
    "        return self.data[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a688971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 100,\n",
    "    'shuffle': True,\n",
    "    'drop_last': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe523c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset(X_train, y_train)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=config['shuffle'],\n",
    "#     num_workers=config['num_workers'],\n",
    "    drop_last=config['drop_last']\n",
    ")\n",
    "\n",
    "validation_set = Dataset(X_valid, y_valid)\n",
    "validation_loader = DataLoader(\n",
    "    validation_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=config['shuffle'],\n",
    "#     num_workers=config['num_workers'],\n",
    "    drop_last=config['drop_last']\n",
    ")\n",
    "\n",
    "test_set = Dataset(X_test, y_test)\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=config['shuffle'],\n",
    "#     num_workers=config['num_workers'],\n",
    "    drop_last=config['drop_last']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e207b",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce28a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''Constructs the ConvLayer with a specified input and output size.\n",
    "           param in_channels: input depth of an image, default value = 1\n",
    "           param out_channels: output depth of the convolutional layer, default value = 256\n",
    "           '''\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # defining a convolutional layer of the specified size\n",
    "        # torch.Size([100, 64, 3])\n",
    "        self.conv1 = nn.Conv1d(in_channels=7, out_channels=64, \n",
    "                              kernel_size=3, stride=1, padding=2)\n",
    "        # torch.Size([100, 128, 5])\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, \n",
    "                              kernel_size=3, stride=1, padding=2)\n",
    "        # torch.Size([100, 256, 7])\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, \n",
    "                              kernel_size=3, stride=1, padding=2)\n",
    "        # torch.Size([100, 512, 9])\n",
    "        self.conv4 = nn.Conv1d(in_channels=256, out_channels=512, \n",
    "                              kernel_size=3, stride=1, padding=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*9, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 16)\n",
    "#         self.conv5 = nn.Conv1d(in_channels=512, out_channels=1024, \n",
    "#                               kernel_size=3, stride=1, padding=2)\n",
    "#         self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Defines the feedforward behavior.\n",
    "           param x: the input to the layer; an input image\n",
    "           return: a relu-activated, convolutional layer\n",
    "           '''\n",
    "        # 将 ReLu 激活应用于 conv 层的输出\n",
    "        features = F.relu(self.conv1(x))\n",
    "#         print(features.shape)\n",
    "        features = F.relu(self.conv2(features))\n",
    "        features = F.relu(self.conv3(features))\n",
    "        features = F.relu(self.conv4(features))\n",
    "        features = features.view(-1, 512*9)\n",
    "        features = F.relu(self.fc1(features))\n",
    "        features = F.relu(self.fc2(features))\n",
    "        features = F.relu(self.fc3(features))\n",
    "        features = self.fc4(features)\n",
    "#         features = self.conv5(features)\n",
    "#         features = F.relu(features) # will have dimensions (batch_size, 20, 20, 256)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110a099",
   "metadata": {},
   "source": [
    "### Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da49e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f16ef60a7ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f16ef60a7ded>\u001b[0m in \u001b[0;36mAttention\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout = 0.3, max_length = T):\n",
    "        super(Attention, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, self.n_layers, bidirectional = True)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        output, hidden = self.gru(input)\n",
    "        output = output.transpose(0,1)\n",
    "        hidden = torch.cat((hidden[0],hidden[1]),1)\n",
    "\n",
    "        attn_weights = self.attn(hidden)\n",
    "        attn_weights = torch.bmm(attn_weights.unsqueeze(1), output)\n",
    "        attn_weights = F.softmax(self.attn(attn_weights.squeeze(1)))\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), output)\n",
    "        attn_applied = attn_applied.squeeze(1)\n",
    "        output = self.attn_combine(attn_applied)\n",
    "        output = F.relu(output)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a57b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_szie1, hidden_szie2, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size, hidden_szie1, 1, dropout = 0.3)\n",
    "        self.r2h = nn.Linear(hidden_szie1, hidden_szie2)\n",
    "        self.h2o = nn.Linear(hidden_szie2, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden, _ = self.rnn(input)\n",
    "        fc1 = F.relu(self.r2h(hidden[T-1]))\n",
    "        output = self.h2o(fc1)\n",
    "        #output = F.softmax(output)\n",
    "\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3539b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=7, hidden_szie1=100, hidden_szie2=100, output_size=16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
