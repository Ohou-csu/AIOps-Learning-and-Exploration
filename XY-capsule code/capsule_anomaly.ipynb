{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-41aa6ee01d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pyplot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import wfdb\n",
    "# import pywt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Model\n",
    "# from Makeing_dataset import load_dataset\n",
    "# from config import cfg\n",
    "# from spactial import load_spactial_dataset\n",
    "# from one import load_one_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, MaxPooling1D,  RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle \n",
    "from tqdm import tqdm \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>UserCpu使用率</th>\n",
       "      <th>内存负载</th>\n",
       "      <th>主机CPU平均负载</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-01 00:05:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>2020-05-31 22:55:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>2020-05-31 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.63</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>2020-05-31 23:05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.61</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>2020-05-31 23:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>2020-05-31 23:50:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  UserCpu使用率   内存负载  主机CPU平均负载  label\n",
       "0      2020-03-01 00:00:00         1.0  81.96        3.0     11\n",
       "1      2020-03-01 00:00:00         1.0  81.96        3.0     11\n",
       "2      2020-03-01 00:00:00         1.0  81.96        3.0     11\n",
       "3      2020-03-01 00:00:00         1.0  81.96        3.0     11\n",
       "4      2020-03-01 00:05:00         1.0  81.92        2.0     11\n",
       "...                    ...         ...    ...        ...    ...\n",
       "11995  2020-05-31 22:55:00         0.0  70.60        2.0     14\n",
       "11996  2020-05-31 23:00:00         0.0  70.63        2.0      0\n",
       "11997  2020-05-31 23:05:00         0.0  70.61        2.0      0\n",
       "11998  2020-05-31 23:30:00         0.0  70.58        2.0      0\n",
       "11999  2020-05-31 23:50:00         0.0  70.62        2.0      0\n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/pro/Library/Mobile Documents/com~apple~CloudDocs/AIOps_xy/jupyter/mul_timeSeries/dataset/dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.将时间序列划分为月、天、小时、分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date'] = pd.to_datetime(dataset['date'], errors='coerce')\n",
    "#月\n",
    "dataset['month'] = dataset['date'].dt.month\n",
    "#天\n",
    "dataset['day'] = dataset['date'].dt.day\n",
    "#小时\n",
    "dataset['hour'] = dataset['date'].dt.hour\n",
    "#分\n",
    "dataset['minute'] = dataset['date'].dt.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.数据集归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.275513</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.348971</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.450329</td>\n",
       "      <td>1.594679</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.005276</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>-1.275513</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.004963</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>0.159583</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>1.307660</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6\n",
       "0     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974\n",
       "1     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974\n",
       "2     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974\n",
       "3     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974\n",
       "4     -1.301023 -1.651728 -1.538896 -1.275513 -0.329070  0.348971 -0.428100\n",
       "...         ...       ...       ...       ...       ...       ...       ...\n",
       "11995  1.181845  1.620713  1.450329  1.594679 -0.368392 -0.005276 -0.428100\n",
       "11996  1.181845  1.620713  1.586202 -1.562533 -0.368392 -0.004337 -0.428100\n",
       "11997  1.181845  1.620713  1.586202 -1.275513 -0.368392 -0.004963 -0.428100\n",
       "11998  1.181845  1.620713  1.586202  0.159583 -0.368392 -0.005901 -0.428100\n",
       "11999  1.181845  1.620713  1.586202  1.307660 -0.368392 -0.004650 -0.428100\n",
       "\n",
       "[12000 rows x 7 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标准化\n",
    "info_data = dataset[['month', 'day', 'hour', 'minute', 'UserCpu使用率', '内存负载', '主机CPU平均负载']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# preprocessing.MinMaxScaler可以把属性缩放到最大值最小值之间\n",
    "np_scaled = min_max_scaler.fit_transform(info_data)\n",
    "info_data = pd.DataFrame(np_scaled)\n",
    "# info_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# info_data = np.nan_to_num(info_data)\n",
    "info_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>-1.538896</td>\n",
       "      <td>-1.275513</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.348971</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.450329</td>\n",
       "      <td>1.594679</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.005276</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>-1.275513</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.004963</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>0.159583</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>1.307660</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974   \n",
       "1     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974   \n",
       "2     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974   \n",
       "3     -1.301023 -1.651728 -1.538896 -1.562533 -0.329070  0.350222 -0.391974   \n",
       "4     -1.301023 -1.651728 -1.538896 -1.275513 -0.329070  0.348971 -0.428100   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11995  1.181845  1.620713  1.450329  1.594679 -0.368392 -0.005276 -0.428100   \n",
       "11996  1.181845  1.620713  1.586202 -1.562533 -0.368392 -0.004337 -0.428100   \n",
       "11997  1.181845  1.620713  1.586202 -1.275513 -0.368392 -0.004963 -0.428100   \n",
       "11998  1.181845  1.620713  1.586202  0.159583 -0.368392 -0.005901 -0.428100   \n",
       "11999  1.181845  1.620713  1.586202  1.307660 -0.368392 -0.004650 -0.428100   \n",
       "\n",
       "       label  \n",
       "0         11  \n",
       "1         11  \n",
       "2         11  \n",
       "3         11  \n",
       "4         11  \n",
       "...      ...  \n",
       "11995     14  \n",
       "11996      0  \n",
       "11997      0  \n",
       "11998      0  \n",
       "11999      0  \n",
       "\n",
       "[12000 rows x 8 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_data['label'] = dataset['label']\n",
    "info_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = shuffle(info_data)\n",
    "\n",
    "var1 = int(len(all_data)*0.6)\n",
    "var2 = int(len(all_data)*0.8)\n",
    "\n",
    "train_data = all_data[0:var1]\n",
    "# train_data = torch.Tensor(train_data)\n",
    "validate_data = all_data[var1:var2]\n",
    "# validate_data = torch.Tensor(validate_data)\n",
    "test_data = all_data[var2:]\n",
    "# test_data = torch.Tensor(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 训练集及其标签 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>0.093574</td>\n",
       "      <td>-0.859527</td>\n",
       "      <td>0.446602</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.379013</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>0.748062</td>\n",
       "      <td>-1.403022</td>\n",
       "      <td>1.020640</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>0.552068</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.124589</td>\n",
       "      <td>0.635086</td>\n",
       "      <td>0.446602</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.354291</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>-0.669996</td>\n",
       "      <td>-0.451905</td>\n",
       "      <td>0.446602</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.433566</td>\n",
       "      <td>1.042707</td>\n",
       "      <td>1.307660</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.328943</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>1.293469</td>\n",
       "      <td>1.178581</td>\n",
       "      <td>1.307660</td>\n",
       "      <td>3.563815</td>\n",
       "      <td>0.914763</td>\n",
       "      <td>3.112250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.124589</td>\n",
       "      <td>1.314455</td>\n",
       "      <td>-0.988494</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.350222</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.215403</td>\n",
       "      <td>-1.131274</td>\n",
       "      <td>-1.562533</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.339270</td>\n",
       "      <td>-0.355848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>1.293469</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>0.733621</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-2.214620</td>\n",
       "      <td>1.811713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>1.402550</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>-0.988494</td>\n",
       "      <td>3.563815</td>\n",
       "      <td>0.914763</td>\n",
       "      <td>3.112250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6\n",
       "1935 -1.301023  0.093574 -0.859527  0.446602 -0.329070  0.379013 -0.391974\n",
       "6494 -0.059589  0.748062 -1.403022  1.020640 -0.368392  0.552068 -0.428100\n",
       "1720 -1.301023 -0.124589  0.635086  0.446602 -0.289748  0.354291 -0.391974\n",
       "9120  1.181845 -0.669996 -0.451905  0.446602 -0.289748  0.563333 -0.391974\n",
       "360  -1.301023 -1.433566  1.042707  1.307660 -0.289748  0.328943 -0.391974\n",
       "...        ...       ...       ...       ...       ...       ...       ...\n",
       "7371 -0.059589  1.293469  1.178581  1.307660  3.563815  0.914763  3.112250\n",
       "1756 -1.301023 -0.124589  1.314455 -0.988494 -0.289748  0.350222 -0.391974\n",
       "497  -1.301023 -1.215403 -1.131274 -1.562533 -0.289748  0.339270 -0.355848\n",
       "7273 -0.059589  1.293469  0.091590  0.733621 -0.368392 -2.214620  1.811713\n",
       "7506 -0.059589  1.402550  0.091590 -0.988494  3.563815  0.914763  3.112250\n",
       "\n",
       "[7200 rows x 7 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_data[[0,1,2,3,4,5,6]]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x).reshape(-1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30102274,  0.09357365, -0.85952656, ..., -0.32907004,\n",
       "         0.37901267, -0.3919739 ],\n",
       "       [-0.05958883,  0.74806194, -1.4030219 , ..., -0.36839212,\n",
       "         0.55206758, -0.42809991],\n",
       "       [-1.30102274, -0.12458912,  0.63508563, ..., -0.28974797,\n",
       "         0.35429054, -0.3919739 ],\n",
       "       ...,\n",
       "       [-1.30102274, -1.21540295, -1.13127423, ..., -0.28974797,\n",
       "         0.3392695 , -0.35584788],\n",
       "       [-0.05958883,  1.29346885,  0.09159029, ..., -0.36839212,\n",
       "        -2.21462036,  1.81171307],\n",
       "       [-0.05958883,  1.40255024,  0.09159029, ...,  3.56381518,\n",
       "         0.91476313,  3.11224964]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "1935      0\n",
       "6494     13\n",
       "1720      0\n",
       "9120      0\n",
       "360       0\n",
       "...     ...\n",
       "7371      1\n",
       "1756      0\n",
       "497       0\n",
       "7273      5\n",
       "7506      1\n",
       "\n",
       "[7200 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_data[['label']]\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [13],\n",
       "       [ 0],\n",
       "       ...,\n",
       "       [ 0],\n",
       "       [ 5],\n",
       "       [ 1]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.array(train_y).reshape(-1, 1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_x)\n",
    "train_y = torch.Tensor(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 测试集及其标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>-0.997240</td>\n",
       "      <td>0.635086</td>\n",
       "      <td>-0.127437</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.496365</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.433566</td>\n",
       "      <td>1.314455</td>\n",
       "      <td>-0.414456</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>-2.155475</td>\n",
       "      <td>2.787116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.450329</td>\n",
       "      <td>-0.988494</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.006527</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-1.651728</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>-0.414456</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.331446</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.124589</td>\n",
       "      <td>-0.859527</td>\n",
       "      <td>0.733621</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.366182</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.620713</td>\n",
       "      <td>1.314455</td>\n",
       "      <td>1.020640</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.010909</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>-0.451833</td>\n",
       "      <td>-0.044284</td>\n",
       "      <td>-0.127437</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.337079</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>-0.342752</td>\n",
       "      <td>1.586202</td>\n",
       "      <td>0.159583</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>-2.170496</td>\n",
       "      <td>2.642611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.888159</td>\n",
       "      <td>-0.859527</td>\n",
       "      <td>0.733621</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>0.373067</td>\n",
       "      <td>2.245225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>1.293469</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>-0.127437</td>\n",
       "      <td>0.968558</td>\n",
       "      <td>-2.214620</td>\n",
       "      <td>1.703335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6\n",
       "4531  -0.059589 -0.997240  0.635086 -0.127437 -0.329070  0.496365 -0.391974\n",
       "365   -1.301023 -1.433566  1.314455 -0.414456 -0.289748 -2.155475  2.787116\n",
       "11977  1.181845  1.620713  1.450329 -0.988494 -0.368392 -0.006527 -0.428100\n",
       "147   -1.301023 -1.651728  1.586202 -0.414456 -0.329070  0.331446 -0.391974\n",
       "1668  -1.301023 -0.124589 -0.859527  0.733621 -0.289748  0.366182 -0.391974\n",
       "...         ...       ...       ...       ...       ...       ...       ...\n",
       "11964  1.181845  1.620713  1.314455  1.020640 -0.368392 -0.010909 -0.428100\n",
       "5191  -0.059589 -0.451833 -0.044284 -0.127437 -0.329070  0.337079 -0.391974\n",
       "5390  -0.059589 -0.342752  1.586202  0.159583 -0.289748 -2.170496  2.642611\n",
       "860   -1.301023 -0.888159 -0.859527  0.733621 -0.368392  0.373067  2.245225\n",
       "7270  -0.059589  1.293469  0.091590 -0.127437  0.968558 -2.214620  1.703335\n",
       "\n",
       "[2400 rows x 7 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = test_data[[0,1,2,3,4,5,6]]\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05958883, -0.99724018,  0.63508563, ..., -0.32907004,\n",
       "         0.49636455, -0.3919739 ],\n",
       "       [-1.30102274, -1.43356571,  1.31445481, ..., -0.28974797,\n",
       "        -2.15547501,  2.7871155 ],\n",
       "       [ 1.18184509,  1.620713  ,  1.45032864, ..., -0.36839212,\n",
       "        -0.00652737, -0.42809991],\n",
       "       ...,\n",
       "       [-0.05958883, -0.34275188,  1.58620248, ..., -0.28974797,\n",
       "        -2.17049605,  2.64261144],\n",
       "       [-1.30102274, -0.8881588 , -0.85952656, ..., -0.36839212,\n",
       "         0.37306684,  2.24522526],\n",
       "       [-0.05958883,  1.29346885,  0.09159029, ...,  0.96855836,\n",
       "        -2.21462036,  1.70333503]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.array(test_x).reshape(-1, 7)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "4531       0\n",
       "365        8\n",
       "11977     14\n",
       "147        0\n",
       "1668       0\n",
       "...      ...\n",
       "11964     14\n",
       "5191       0\n",
       "5390       8\n",
       "860        6\n",
       "7270       2\n",
       "\n",
       "[2400 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test_data[['label']]\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 8],\n",
       "       [14],\n",
       "       ...,\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 2]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = np.array(test_y).reshape(-1, 1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 验证集及其标签 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.888159</td>\n",
       "      <td>-0.587779</td>\n",
       "      <td>-0.701475</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.348345</td>\n",
       "      <td>-0.355848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>1.402550</td>\n",
       "      <td>1.042707</td>\n",
       "      <td>1.020640</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.465384</td>\n",
       "      <td>-0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.888159</td>\n",
       "      <td>0.635086</td>\n",
       "      <td>-0.701475</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.340521</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>-0.997240</td>\n",
       "      <td>-1.131274</td>\n",
       "      <td>0.446602</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>-1.301023</td>\n",
       "      <td>0.966225</td>\n",
       "      <td>-1.403022</td>\n",
       "      <td>1.307660</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-2.214620</td>\n",
       "      <td>0.258294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>0.966225</td>\n",
       "      <td>0.363338</td>\n",
       "      <td>1.594679</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>-0.006527</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>-0.779077</td>\n",
       "      <td>-1.267148</td>\n",
       "      <td>1.020640</td>\n",
       "      <td>-0.329070</td>\n",
       "      <td>0.602451</td>\n",
       "      <td>-0.391974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11661</th>\n",
       "      <td>1.181845</td>\n",
       "      <td>1.511632</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>1.594679</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-2.214620</td>\n",
       "      <td>-0.500352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>-0.124589</td>\n",
       "      <td>-1.267148</td>\n",
       "      <td>-0.414456</td>\n",
       "      <td>3.563815</td>\n",
       "      <td>0.914763</td>\n",
       "      <td>3.112250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>-0.059589</td>\n",
       "      <td>-0.342752</td>\n",
       "      <td>0.499212</td>\n",
       "      <td>-0.127437</td>\n",
       "      <td>-0.289748</td>\n",
       "      <td>0.413749</td>\n",
       "      <td>-0.355848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6\n",
       "870   -1.301023 -0.888159 -0.587779 -0.701475 -0.289748  0.348345 -0.355848\n",
       "3357  -1.301023  1.402550  1.042707  1.020640 -0.329070  0.465384 -0.428100\n",
       "912   -1.301023 -0.888159  0.635086 -0.701475 -0.329070  0.340521 -0.391974\n",
       "721   -1.301023 -0.997240 -1.131274  0.446602 -0.289748  0.352100 -0.391974\n",
       "2805  -1.301023  0.966225 -1.403022  1.307660 -0.368392 -2.214620  0.258294\n",
       "...         ...       ...       ...       ...       ...       ...       ...\n",
       "11086  1.181845  0.966225  0.363338  1.594679 -0.329070 -0.006527 -0.391974\n",
       "8964   1.181845 -0.779077 -1.267148  1.020640 -0.329070  0.602451 -0.391974\n",
       "11661  1.181845  1.511632  0.091590  1.594679 -0.368392 -2.214620 -0.500352\n",
       "5510  -0.059589 -0.124589 -1.267148 -0.414456  3.563815  0.914763  3.112250\n",
       "5330  -0.059589 -0.342752  0.499212 -0.127437 -0.289748  0.413749 -0.355848\n",
       "\n",
       "[2400 rows x 7 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_x = validate_data[[0,1,2,3,4,5,6]]\n",
    "validate_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30102274, -0.8881588 , -0.58777889, ..., -0.28974797,\n",
       "         0.34834472, -0.35584788],\n",
       "       [-1.30102274,  1.40255024,  1.04270714, ..., -0.32907004,\n",
       "         0.46538366, -0.42809991],\n",
       "       [-1.30102274, -0.8881588 ,  0.63508563, ..., -0.32907004,\n",
       "         0.34052126, -0.3919739 ],\n",
       "       ...,\n",
       "       [ 1.18184509,  1.51163162,  0.09159029, ..., -0.36839212,\n",
       "        -2.21462036, -0.50035194],\n",
       "       [-0.05958883, -0.12458912, -1.26714807, ...,  3.56381518,\n",
       "         0.91476313,  3.11224964],\n",
       "       [-0.05958883, -0.34275188,  0.4992118 , ..., -0.28974797,\n",
       "         0.41374883, -0.35584788]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_x = np.array(validate_x).reshape(-1, 7)\n",
    "validate_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_y = validate_data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_y = np.array(validate_y).reshape(-1, 1)\n",
    "validate_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 CNN- LSTM并行提取层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 构建CNN模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建CNN模型\n",
    "def buildModel():\n",
    "    # 输入，纬度为（7，1）\n",
    "    input_cnn = tf.keras.layers.Input(shape=(7,1))\n",
    "    # cnn+lstm并行提取特征\n",
    "    # 第一层cnn，提取特征\n",
    "    cnn = tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='SAME', activation='relu')(input_cnn)\n",
    "    # 第一层lstm\n",
    "    lstm_output = tf.keras.layers.LSTM(32)(input_cnn)\n",
    "    cnn_fla = tf.keras.layers.Flatten()(cnn)\n",
    "    lstm_fla = tf.keras.layers.Flatten()(lstm_output)\n",
    "    # 将cnn和lstm的输出拼接起来,shape=(None, 256)\n",
    "    fe_output = tf.concat([cnn_fla,lstm_fla],axis=1)\n",
    "    # 随机让20%的节点停止工作\n",
    "    dr_output = tf.keras.layers.Dropout(rate=0.2)(fe_output)\n",
    "    # 全连接层,16 个节点,一共有16类\n",
    "    output = tf.keras.layers.Dense(16, activation='softmax')(dr_output)\n",
    "    newModel = Model(input_cnn,output)\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵\n",
    "def plotHeatMap(Y_test, Y_pred):\n",
    "    con_mat = confusion_matrix(Y_test, Y_pred)\n",
    "    # 归一化\n",
    "    # con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "    # con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
    "    FP = con_mat.sum(axis=0) - np.diag(con_mat)\n",
    "    FN = con_mat.sum(axis=1) - np.diag(con_mat)\n",
    "    TP = np.diag(con_mat)\n",
    "    TN = con_mat.sum() - (FN + FP + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    print(\"FP\", FP)\n",
    "    print(\"FN\", FN)\n",
    "    print(\"TP\", TP)\n",
    "    print(\"TN\", TN)\n",
    "    each_acc = TP / (TP + FN)\n",
    "    total_acc = np.sum(np.diag(con_mat)) / con_mat.sum()\n",
    "    acc = (TP + TN) / (FP + FN + TP + TN)\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    ppr = TP / (TP + FP)\n",
    "    f1 = 2 / (1 / sen + 1 / ppr)\n",
    "    g = np.sqrt(sen + ppr)\n",
    "    print(\"total_acc\", total_acc)\n",
    "    print(\"each_acc\", each_acc)\n",
    "    print(\"acc\", acc)\n",
    "    print(\"sen\", sen)\n",
    "    print(\"spe\", spe)\n",
    "    print(\"ppr\", ppr)\n",
    "    print(\"f1\", f1)\n",
    "    print(\"g\", g)\n",
    "    # 绘图\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    seaborn.heatmap(con_mat, annot=True, fmt='.20g', cmap='Blues')\n",
    "    plt.ylim(0, 5)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(\"lstm+cnn\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tr_num = train_x.shape[0] // batch_size \n",
    "batch_tr_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_val_num = validate_x.shape[0] // batch_size \n",
    "batch_val_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 训练cnn-LSTM模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 1.6112 - accuracy: 0.6011\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 1.1109 - accuracy: 0.6963\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 1.0227 - accuracy: 0.7051\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.9807 - accuracy: 0.7154\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.9512 - accuracy: 0.7165\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.9242 - accuracy: 0.7200\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.9116 - accuracy: 0.7188\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8917 - accuracy: 0.7249\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.8848 - accuracy: 0.7212\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8730 - accuracy: 0.7239\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8586 - accuracy: 0.7232\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8450 - accuracy: 0.7240\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8323 - accuracy: 0.7271\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8273 - accuracy: 0.7364\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8151 - accuracy: 0.7315\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.8089 - accuracy: 0.7354\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7979 - accuracy: 0.7368\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7904 - accuracy: 0.7428\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7767 - accuracy: 0.7428\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7680 - accuracy: 0.7429\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7667 - accuracy: 0.7435\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7581 - accuracy: 0.7475\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7453 - accuracy: 0.7471\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7425 - accuracy: 0.7524\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.7359 - accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7363 - accuracy: 0.7574\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7310 - accuracy: 0.7561\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7171 - accuracy: 0.7589\n",
      "Epoch 29/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7067 - accuracy: 0.7638\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7044 - accuracy: 0.7638\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.7016 - accuracy: 0.7642\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6989 - accuracy: 0.7661\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6911 - accuracy: 0.7692\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6872 - accuracy: 0.7688\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6861 - accuracy: 0.7718\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6783 - accuracy: 0.7749\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6666 - accuracy: 0.7771\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6716 - accuracy: 0.7760\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6625 - accuracy: 0.7756\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6629 - accuracy: 0.7797\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6504 - accuracy: 0.7781\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6562 - accuracy: 0.7794\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6496 - accuracy: 0.7822\n",
      "Epoch 44/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6439 - accuracy: 0.7833\n",
      "Epoch 45/50\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.6352 - accuracy: 0.7851\n",
      "Epoch 46/50\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.6391 - accuracy: 0.7840\n",
      "Epoch 47/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.7868\n",
      "Epoch 48/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6283 - accuracy: 0.7890\n",
      "Epoch 49/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.7862\n",
      "Epoch 50/50\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.6217 - accuracy: 0.7911\n",
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model = buildModel()\n",
    "model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "# 定义TensorBoard对象\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# 训练与验证\n",
    "model.fit(train_x, train_y, epochs=50,\n",
    "                batch_size=32,\n",
    "                callbacks=[tensorboard_callback])\n",
    "x = model.output_shape\n",
    "print(x)\n",
    "# model.save(filepath=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP [323.   0.   0.   4.   5.  13.   0.   6.   6.   3.   7.  40.  12.   0.\n",
      "  26.   3.]\n",
      "FN [48.  0.  8.  0.  2.  8.  6. 35. 10.  0. 40. 26. 56. 81. 55. 73.]\n",
      "TP [1151.   84.   77.   81.   67.   85.   78.   39.   69.   77.   40.   53.\n",
      "   20.    0.   27.    4.]\n",
      "TN [ 878. 2316. 2315. 2315. 2326. 2294. 2316. 2320. 2315. 2320. 2313. 2281.\n",
      " 2312. 2319. 2292. 2320.]\n",
      "total_acc 0.8133333333333334\n",
      "each_acc [0.95996664 1.         0.90588235 1.         0.97101449 0.91397849\n",
      " 0.92857143 0.52702703 0.87341772 1.         0.5        0.67088608\n",
      " 0.26315789 0.         0.32926829 0.05194805]\n",
      "acc [0.84541667 1.         0.99666667 0.99833333 0.99708333 0.99125\n",
      " 0.9975     0.98291667 0.99333333 0.99875    0.98041667 0.9725\n",
      " 0.97166667 0.96625    0.96625    0.96833333]\n",
      "sen [0.95996664 1.         0.90588235 1.         0.97101449 0.91397849\n",
      " 0.92857143 0.52702703 0.87341772 1.         0.5        0.67088608\n",
      " 0.26315789 0.         0.32926829 0.05194805]\n",
      "spe [0.73105745 1.         1.         0.99827512 0.997855   0.99436498\n",
      " 1.         0.99742046 0.99741491 0.99870857 0.99698276 0.98276605\n",
      " 0.99483649 1.         0.98878343 0.99870857]\n",
      "ppr [0.78086839 1.         1.         0.95294118 0.93055556 0.86734694\n",
      " 1.         0.86666667 0.92       0.9625     0.85106383 0.56989247\n",
      " 0.625             nan 0.50943396 0.57142857]\n",
      "f1 [0.86120464 1.         0.95061728 0.97590361 0.95035461 0.89005236\n",
      " 0.96296296 0.65546218 0.8961039  0.98089172 0.62992126 0.61627907\n",
      " 0.37037037        nan 0.4        0.0952381 ]\n",
      "g [1.31940707 1.41421356 1.38053698 1.39747672 1.37897427 1.33466304\n",
      " 1.38873015 1.18054805 1.33918547 1.40089257 1.16235271 1.1139024\n",
      " 0.94242129        nan 0.91580689 0.78954203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = model.predict(test_x)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    # # 绘制混淆矩阵\n",
    "plotHeatMap(test_y, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 cnn网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_cnn():\n",
    "    newModel = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(7200, 7)),\n",
    "        # 第一个卷积层, 4 个 21x1 卷积核\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=7, strides=2, padding='SAME', activation='relu'),\n",
    "        tf.keras.layers.AveragePooling1D(pool_size=1, strides=2, padding='SAME'),\n",
    "        # 第一个池化层, 最大池化,4 个 3x1 卷积核, 步长为 2\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        # 全连接层,5 个节点\n",
    "        tf.keras.layers.Dense(16, activation='softmax')\n",
    "    ])\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        replication_mode=InputReplicationMode.PER_WORKER):\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=float32, numpy=2.0>\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        @property\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        to scalar coefficients.\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        keras_tensor.keras_tensor_from_tensor, outputs)\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        list_inputs = []\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [32, 7]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-f95c18dbe35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m model_cnn.fit(train_x, train_y, epochs=20,\n\u001b[1;32m     10\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 callbacks=[tensorboard_callback])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    847\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0mwrite_scalar_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \"\"\"\n\u001b[1;32m    579\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m     self._function_spec = function_lib.FunctionSpec.from_function_and_signature(\n\u001b[1;32m    582\u001b[0m         \u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"Returns key instance to track call stats and retracings.\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0mThe\u001b[0m \u001b[0mkey\u001b[0m \u001b[0minstance\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meffort\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpreserve\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0mconsistency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \"\"\"\n\u001b[1;32m    629\u001b[0m     \u001b[0mtarget_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m   \u001b[0m__slots__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"func_graph\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m       \u001b[0;31m# inspect.ismethod() and inspect.isfunction() both return False on a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0;31m# functools.partial-wrapped function. We set it to False to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m       \u001b[0;31m# maintain consistency with prior versions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m       \u001b[0mis_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m       inputs, flat_inputs, filtered_flat_inputs = _convert_inputs_to_signature(\n\u001b[1;32m   2776\u001b[0m           inputs, self._input_signature, self._flat_input_signature)\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mvarargs\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0margs\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mcanonicalized\u001b[0m \u001b[0mordering\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwell\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfull\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m                 options=autograph.ConversionOptions(\n\u001b[1;32m    980\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                 ))\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mflag\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mno\u001b[0m \u001b[0meffect\u001b[0m \u001b[0mon\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0minto\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0mtransformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m   \u001b[0;32mas\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0mare\u001b[0m \u001b[0mnever\u001b[0m \u001b[0mexecuted\u001b[0m \u001b[0meagerly\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mare\u001b[0m \u001b[0malways\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m   \u001b[0mexecuted\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0mTensorflow\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        replication_mode=InputReplicationMode.PER_WORKER):\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=float32, numpy=2.0>\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        @property\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        to scalar coefficients.\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        keras_tensor.keras_tensor_from_tensor, outputs)\n    /Users/pro/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        list_inputs = []\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [32, 7]\n"
     ]
    }
   ],
   "source": [
    "log_dir_cnn=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_cnn = buildModel_cnn()\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "# 定义TensorBoard对象\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# 训练与验证\n",
    "model_cnn.fit(train_x, train_y, epochs=20,\n",
    "                batch_size=32,\n",
    "                callbacks=[tensorboard_callback])\n",
    "x = model.output_shape\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-45fa171f2940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# # 绘制混淆矩阵\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplotHeatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "Y_pred = model_cnn.predict(test_x)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    # # 绘制混淆矩阵\n",
    "plotHeatMap(test_y, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 LSTM层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel_LSTM():\n",
    "    newModel = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(7, 1)),\n",
    "        # 第一个卷积层, 4 个 21x1 卷积核\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        # 全连接层,5 个节点\n",
    "        tf.keras.layers.Dense(16, activation='softmax')\n",
    "    ])\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8722\n",
      "Epoch 2/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8729\n",
      "Epoch 3/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8687\n",
      "Epoch 4/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8699\n",
      "Epoch 5/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8715\n",
      "Epoch 6/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8701\n",
      "Epoch 7/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3820 - accuracy: 0.8708\n",
      "Epoch 8/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8726\n",
      "Epoch 9/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8732\n",
      "Epoch 10/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8747\n",
      "Epoch 11/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8712\n",
      "Epoch 12/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8740\n",
      "Epoch 13/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8733\n",
      "Epoch 14/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8732\n",
      "Epoch 15/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8701\n",
      "Epoch 16/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8774\n",
      "Epoch 17/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8737\n",
      "Epoch 18/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8701\n",
      "Epoch 19/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8726\n",
      "Epoch 20/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8754\n",
      "Epoch 21/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8724\n",
      "Epoch 22/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8733\n",
      "Epoch 23/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8782\n",
      "Epoch 24/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8757\n",
      "Epoch 25/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8737\n",
      "Epoch 26/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8726\n",
      "Epoch 27/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8726\n",
      "Epoch 28/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8800\n",
      "Epoch 29/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8718\n",
      "Epoch 30/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8756\n",
      "Epoch 31/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8788\n",
      "Epoch 32/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8790\n",
      "Epoch 33/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8813\n",
      "Epoch 34/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8785\n",
      "Epoch 35/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8801\n",
      "Epoch 36/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8806\n",
      "Epoch 37/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8754\n",
      "Epoch 38/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3598 - accuracy: 0.8771\n",
      "Epoch 39/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8786\n",
      "Epoch 40/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8767\n",
      "Epoch 41/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8836\n",
      "Epoch 42/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3575 - accuracy: 0.8796\n",
      "Epoch 43/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8829\n",
      "Epoch 44/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8819\n",
      "Epoch 45/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8817\n",
      "Epoch 46/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8819\n",
      "Epoch 47/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8811\n",
      "Epoch 48/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8806\n",
      "Epoch 49/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8828\n",
      "Epoch 50/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8799\n",
      "Epoch 51/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8828\n",
      "Epoch 52/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8814\n",
      "Epoch 53/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8819\n",
      "Epoch 54/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8849\n",
      "Epoch 55/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8822\n",
      "Epoch 56/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8840\n",
      "Epoch 57/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8840\n",
      "Epoch 58/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8828\n",
      "Epoch 59/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8815\n",
      "Epoch 60/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8833\n",
      "Epoch 61/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8813\n",
      "Epoch 62/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8861\n",
      "Epoch 63/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8853\n",
      "Epoch 64/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8832\n",
      "Epoch 65/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8853\n",
      "Epoch 66/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8860\n",
      "Epoch 67/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8871\n",
      "Epoch 68/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8822\n",
      "Epoch 69/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8886\n",
      "Epoch 70/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8897\n",
      "Epoch 71/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8865\n",
      "Epoch 72/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8881\n",
      "Epoch 73/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8867\n",
      "Epoch 74/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8875\n",
      "Epoch 75/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8886\n",
      "Epoch 76/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8863\n",
      "Epoch 77/200\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.8879\n",
      "Epoch 78/200\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.3204 - accuracy: 0.8918\n",
      "Epoch 79/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8894\n",
      "Epoch 80/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8913\n",
      "Epoch 81/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8868\n",
      "Epoch 82/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8888\n",
      "Epoch 83/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8900\n",
      "Epoch 84/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8911\n",
      "Epoch 85/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8922\n",
      "Epoch 86/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8851\n",
      "Epoch 87/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8913\n",
      "Epoch 88/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8922\n",
      "Epoch 89/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3187 - accuracy: 0.8907\n",
      "Epoch 90/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8903\n",
      "Epoch 91/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8894\n",
      "Epoch 92/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8890\n",
      "Epoch 93/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8942\n",
      "Epoch 94/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8922\n",
      "Epoch 95/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8913\n",
      "Epoch 96/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8931\n",
      "Epoch 97/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8929\n",
      "Epoch 98/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8906\n",
      "Epoch 99/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8935\n",
      "Epoch 100/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8942\n",
      "Epoch 101/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8931\n",
      "Epoch 102/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8950\n",
      "Epoch 103/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8947\n",
      "Epoch 104/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8922\n",
      "Epoch 105/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8940\n",
      "Epoch 106/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3126 - accuracy: 0.8929\n",
      "Epoch 107/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8971\n",
      "Epoch 108/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.8971\n",
      "Epoch 109/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8928\n",
      "Epoch 110/200\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.3101 - accuracy: 0.8921\n",
      "Epoch 111/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8892\n",
      "Epoch 112/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8946\n",
      "Epoch 113/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8978\n",
      "Epoch 114/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8944\n",
      "Epoch 115/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8972\n",
      "Epoch 116/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8958\n",
      "Epoch 117/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8972\n",
      "Epoch 118/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8939\n",
      "Epoch 119/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8981\n",
      "Epoch 120/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8975\n",
      "Epoch 121/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8947\n",
      "Epoch 122/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8936\n",
      "Epoch 123/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8936\n",
      "Epoch 124/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8986\n",
      "Epoch 125/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8968\n",
      "Epoch 126/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8976\n",
      "Epoch 127/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8986\n",
      "Epoch 128/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.9010\n",
      "Epoch 129/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8958\n",
      "Epoch 130/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8974\n",
      "Epoch 131/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8999\n",
      "Epoch 132/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8967\n",
      "Epoch 133/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.9043\n",
      "Epoch 134/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8967\n",
      "Epoch 135/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8976\n",
      "Epoch 136/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8968\n",
      "Epoch 137/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8982\n",
      "Epoch 138/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8949\n",
      "Epoch 139/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.9017\n",
      "Epoch 140/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8993\n",
      "Epoch 141/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.9010\n",
      "Epoch 142/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8996\n",
      "Epoch 143/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.9006\n",
      "Epoch 144/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9014\n",
      "Epoch 145/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9013\n",
      "Epoch 146/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.9017\n",
      "Epoch 147/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8994\n",
      "Epoch 148/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.9044\n",
      "Epoch 149/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8957\n",
      "Epoch 150/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.9001\n",
      "Epoch 151/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9028\n",
      "Epoch 152/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8969\n",
      "Epoch 153/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.9021\n",
      "Epoch 154/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.9001\n",
      "Epoch 155/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.9050\n",
      "Epoch 156/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9007\n",
      "Epoch 157/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.9065\n",
      "Epoch 158/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8963\n",
      "Epoch 159/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9015\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.9019\n",
      "Epoch 161/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9051\n",
      "Epoch 162/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.9015\n",
      "Epoch 163/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9003\n",
      "Epoch 164/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9028\n",
      "Epoch 165/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9050\n",
      "Epoch 166/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9040\n",
      "Epoch 167/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.9024\n",
      "Epoch 168/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.9033\n",
      "Epoch 169/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9047\n",
      "Epoch 170/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.9019\n",
      "Epoch 171/200\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.9036\n",
      "Epoch 172/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.9019\n",
      "Epoch 173/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9011\n",
      "Epoch 174/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9035\n",
      "Epoch 175/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9017\n",
      "Epoch 176/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9051\n",
      "Epoch 177/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.9018\n",
      "Epoch 178/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9040\n",
      "Epoch 179/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.9039\n",
      "Epoch 180/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9058\n",
      "Epoch 181/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.9086\n",
      "Epoch 182/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9090\n",
      "Epoch 183/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.9028\n",
      "Epoch 184/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9049\n",
      "Epoch 185/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9056\n",
      "Epoch 186/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9067\n",
      "Epoch 187/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9046\n",
      "Epoch 188/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9036\n",
      "Epoch 189/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.9067\n",
      "Epoch 190/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9075\n",
      "Epoch 191/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9051\n",
      "Epoch 192/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9096\n",
      "Epoch 193/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.9093\n",
      "Epoch 194/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.9099\n",
      "Epoch 195/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9050\n",
      "Epoch 196/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9061\n",
      "Epoch 197/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9094\n",
      "Epoch 198/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9072\n",
      "Epoch 199/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9089\n",
      "Epoch 200/200\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7febf69b34e0>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir_cnn=\"logs_LSTM/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_LSTM = buildModel_LSTM()\n",
    "model_LSTM.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "# 定义TensorBoard对象\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# 训练与验证\n",
    "model_cnn.fit(train_x, train_y, epochs=200,\n",
    "                batch_size=32,\n",
    "                callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 胶囊网络层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 胶囊层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsLayer(object):\n",
    "    ''' Capsule layer 类别参数有：\n",
    "        Args:\n",
    "            input: 一个4维张量[batchsize, row, cel,filters][128,none,430,64]\n",
    "            num_outputs: 当前层的Capsule单元数量\n",
    "            vec_len: 一个Capsule输出向量的长度\n",
    "            layer_type: 选择'FC' 或 \"CONV\", 以确定是用全连接层还是卷积层\n",
    "            with_routing: 当前Capsule是否从较低层级中Routing而得出输出向量\n",
    "\n",
    "        Returns:\n",
    "            一个四维张量\n",
    "        '''\n",
    "    def __init__(self, num_outputs, vec_len, with_routing=True, layer_type='FC'):\n",
    "        # 当前层的胶囊数量\n",
    "        self.num_outputs = num_outputs\n",
    "        # 胶囊长度\n",
    "        self.vec_len = vec_len\n",
    "        # 是否进行动态路由\n",
    "        self.with_routing = with_routing\n",
    "        # 层的类型\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "    def __call__(self, input, kernel_size=None, stride=None):\n",
    "        '''\n",
    "        当“Layer_type”选择的是“CONV”，将使用 'kernel_size' 和 'stride'\n",
    "        '''\n",
    "        capsules = []\n",
    "        if self.layer_type == 'CONV':\n",
    "            self.kernel_size = kernel_size\n",
    "            self.stride = stride\n",
    "            \n",
    "            # 不进行动态路由\n",
    "            if not self.with_routing:\n",
    "                # 第一层卷积\n",
    "                # 输入，胶囊数量*胶囊长度，卷机核大小，卷积步长\n",
    "                capsules = tf.contrib.layers.conv1d(input, self.num_outputs * self.vec_len, self.kernel_size, self.stride, padding=\"VALID\",\n",
    "                 activation_fn=tf.nn.relu)\n",
    "                print(\"第二次一维卷积维数：\",capsules.get_shape())\n",
    "                capsules = tf.reshape(capsules, (capsules.shape[0], -1, self.vec_len,1))\n",
    "                # 进行压缩\n",
    "                capsules = squash(capsules)\n",
    "\n",
    "                # assert capsules.get_shape() == [cfg.batch_size, 1152, 8, 1]\n",
    "                return (capsules)\n",
    "\n",
    "        # the PrimaryCaps layer, a convolutional layer\n",
    "        # 全连接层\n",
    "        if self.layer_type == 'FC':\n",
    "            if self.with_routing:\n",
    "                print(\"FC.input: \",input)\n",
    "                self.input = tf.reshape(input, shape=(input.shape[0], -1, 1, input.shape[-2].value, 1))\n",
    "                print(\"FC_input 维数：\",self.input.shape)\n",
    "                # 动态路由\n",
    "                with tf.variable_scope('routing'):\n",
    "                    b_IJ = tf.constant(\n",
    "                        np.zeros([cfg.batch_size, input.shape[1].value, self.num_outputs, 1, 1], dtype=np.float32))\n",
    "                    print(\"b_ij:\",b_IJ.shape)\n",
    "                    capsules = routing(self.input, b_IJ)\n",
    "                    capsules = tf.squeeze(capsules, axis=1)\n",
    "\n",
    "            return(capsules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 动态路由层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing(input, b_IJ):\n",
    "    print(\"dynamic routing!!!!!!\")\n",
    "    # W: [num_caps_i, num_caps_j, len_u_i, len_v_j]\n",
    "    ###############################################\n",
    "    W = tf.get_variable('Weight', shape=(1, input.shape[1], 5, 8, 8), dtype=tf.float32,\n",
    "                        initializer=tf.random_normal_initializer(stddev=cfg.stddev))\n",
    "    # W = tf.get_variable('Weight', shape=(1, input.shape[1], 2, 8, 8), dtype=tf.float32,\n",
    "    #                     initializer=tf.random_normal_initializer(stddev=cfg.stddev))\n",
    "    print(\"W的维数:\",W.shape)\n",
    "    # Eq.2, calc u_hat\n",
    "    # do tiling for input and W before matmul\n",
    "    # input => [batch_size, 1152, 10, 8, 1]\n",
    "    # W => [batch_size, 1152, 10, 8, 16]\n",
    "    ######################################\n",
    "    input = tf.tile(input, [1, 1, 5, 1, 1])\n",
    "    # input = tf.tile(input, [1, 1, 2, 1, 1])\n",
    "    a_i = tf.sqrt(tf.reduce_sum(tf.square(input), axis=-2, keep_dims=True))\n",
    "    a_i = tf.nn.softmax(a_i, axis=2)\n",
    "    print(\"a_i: \", a_i.shape)\n",
    "    print(\"扩维的输入维数：\", input.shape)\n",
    "    W = tf.tile(W, [cfg.batch_size,1, 1, 1, 1])\n",
    "    print(\"W最终维数：\",W.shape)\n",
    "    u_hat = tf.matmul(W, input, transpose_a=True)\n",
    "    # assert u_hat.get_shape() == [cfg.batch_size, 1152, 10, 16, 1]\n",
    "    print(\"u的维数：\",u_hat.shape)\n",
    "    # In forward, u_hat_stopped = u_hat; in backward, no gradient passed back from u_hat_stopped to u_hat\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
    "    ##########################################\n",
    "    # s_J = tf.reduce_mean(u_hat_stopped, axis=2, keep_dims=True)\n",
    "    # print(\"未循环s_J: \", s_J.shape)\n",
    "    # b_IJ = tf.reduce_sum(tf.square(tf.subtract(u_hat_stopped, s_J)), axis=1, keep_dims=True)\n",
    "    # print(\"未循环b_IJ: \", b_IJ.shape)\n",
    "    # line 3,for r iterations do\n",
    "    for r_iter in range(cfg.iter_routing):\n",
    "        with tf.variable_scope('iter_' + str(r_iter)):\n",
    "            # line 4:\n",
    "            # => [batch_size, 1152, 10, 1, 1]\n",
    "            # #########################method 1 :leaky_softmax######################\n",
    "            # leak = tf.zeros_like(b_IJ, optimize=True)\n",
    "            # print(\"leak1\",leak.shape)\n",
    "            # leak = tf.reduce_sum(leak, axis=2, keep_dims=True)\n",
    "            # print(\"leak2\",leak.shape)\n",
    "            #\n",
    "            # leaky_logits = tf.concat([leak, b_IJ], axis=2)\n",
    "            # print(\"leaky_logits\",leaky_logits.shape)\n",
    "            #\n",
    "            # leaky_routing = tf.nn.softmax(leaky_logits, axis=2)\n",
    "            # print(\"leak_routing\",leaky_routing.shape)\n",
    "            # #####################\n",
    "            # c_IJ = tf.split(leaky_routing, [1, 5], axis=2)[1]\n",
    "            # c_IJ = c_IJ*a_i\n",
    "            ##########################METHOD 2#####################################################\n",
    "            # b_IJ = tf.multiply(b_IJ,a_i)\n",
    "            # a_i = tf.nn.softmax(a_i,axis=2)\n",
    "            # print(\"softmax_ai:\",a_i.shape)\n",
    "            c_IJ = tf.nn.softmax(b_IJ, dim=2)*a_i\n",
    "            # print(\"C_IJ:\", c_IJ.shape)\n",
    "            # c_IJ = tf.multiply(c_IJ,a_i)\n",
    "            # print(\"C_ij: \",c_IJ.shape)\n",
    "            #########################METHOD 3 KMEANS_ROUTING#########################################\n",
    "            # b_IJ = tf.reduce_sum(tf.square(tf.subtract(u_hat_stopped, s_J)), axis=1, keep_dims=True)\n",
    "            # print(\"循环b_IJ: \", b_IJ.shape)\n",
    "            # c_IJ = tf.nn.sigmoid(b_IJ)\n",
    "            # print(\"sigmoid_C_ij: \", c_IJ.shape)\n",
    "            # At last iteration, use `u_hat` in order to receive gradients from the following graph\n",
    "            if r_iter == cfg.iter_routing - 1:\n",
    "                # line 5:\n",
    "                # weighting u_hat with c_IJ, element-wise in the last two dims\n",
    "                # => [batch_size, 1152, 10, 16, 1]\n",
    "                s_J = tf.multiply(c_IJ, u_hat)\n",
    "                print(\"multi_s_J:\",s_J.shape)\n",
    "                # then sum in the second dim, resulting in [batch_size, 1, 10, 16, 1]\n",
    "                s_J = tf.reduce_sum(s_J, axis=1, keep_dims=True)\n",
    "                # assert s_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "                print(\"最后一次循环s_J的维数：\", s_J.shape)\n",
    "                # line 6:\n",
    "                # squash using Eq.1,\n",
    "                v_J = squash(s_J)\n",
    "                # assert v_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "            elif r_iter < cfg.iter_routing - 1:  # Inner iterations, do not apply backpropagation\n",
    "                s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
    "                print(\"multi_s_J:\",s_J.shape)\n",
    "                s_J = tf.reduce_sum(s_J, axis=1, keep_dims=True)\n",
    "                print(\"循环s_J的维数：\",s_J.shape)\n",
    "                v_J = squash(s_J)\n",
    "\n",
    "                # line 7:\n",
    "                # reshape & tile v_j from [batch_size ,1, 10, 16, 1] to [batch_size, 1152, 10, 16, 1]\n",
    "                # then matmul in the last tow dim: [16, 1].T x [16, 1] => [1, 1], reduce mean in the\n",
    "                # batch_size dim, resulting in [1, 1152, 10, 1, 1]\n",
    "\n",
    "                v_J_tiled = tf.tile(v_J, [1, input.shape[1], 1, 1, 1])\n",
    "                print(\"v的维数：\",v_J_tiled.shape)\n",
    "                u_produce_v = tf.matmul(u_hat_stopped, v_J_tiled, transpose_a=True)\n",
    "\n",
    "                # assert u_produce_v.get_shape() == [cfg.batch_size, 1152, 10, 1, 1]\n",
    "                # b_IJ += tf.reduce_sum(u_produce_v, axis=0, keep_dims=True)\n",
    "\n",
    "                b_IJ += u_produce_v\n",
    "\n",
    "    return(v_J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 压缩函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector):\n",
    "    '''Squashing function corresponding to Eq. 1\n",
    "    Args:\n",
    "        vector: A tensor with shape [batch_size, 1, num_caps, vec_len, 1] or [batch_size, num_caps, vec_len, 1].\n",
    "    Returns:\n",
    "        A tensor with the same shape as vector but squashed in 'vec_len' dimension.\n",
    "    '''\n",
    "    ###########method1 squansh function\n",
    "    vec_squared_norm = tf.reduce_sum(tf.square(vector), -2, keep_dims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
    "    vec_squashed = scalar_factor * vector  # element wise\n",
    "    #############method2 strong squansh function#############\n",
    "    # vec_squared_norm_a = tf.reduce_sum(tf.square(vector), -2, keep_dims=True)\n",
    "    # vec_squared_norm_b = tf.sqrt(vec_squared_norm_a + epsilon)\n",
    "    # scalar_factor = vec_squared_norm_a/vec_squared_norm_b\n",
    "    # vec_squashed = scalar_factor*vector\n",
    "\n",
    "\n",
    "    return(vec_squashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist:\n",
    "    def __init__(self, batch_size):\n",
    "        dataset_transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "\n",
    "        train_dataset = datasets.MNIST('../data', train=True, download=True, transform=dataset_transform)\n",
    "        test_dataset = datasets.MNIST('../data', train=False, download=True, transform=dataset_transform)\n",
    "        \n",
    "        self.train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    # 输入通道是1，输出是256\n",
    "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=1\n",
    "                             )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 子胶囊层\n",
    "class PrimaryCaps(nn.Module):\n",
    "    # num_capsules为胶囊的个数\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0) \n",
    "                          for _ in range(num_capsules)])\n",
    "    \n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        print('(1)u:',u)\n",
    "        u = torch.stack(u, dim=1)\n",
    "        print('(2)u:',u)\n",
    "        u = u.view(x.size(0), 32 * 6 * 6, -1)\n",
    "        print('(3)u:',u)\n",
    "        # 压缩函数\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = ConvLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (conv): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_capsules.forward(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_capsules = PrimaryCaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = torch.from_numpy(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1818, -0.6700, -1.1313,  ..., -0.2504,  0.5615, -0.3558],\n",
       "        [ 1.1818, -0.1246,  0.0916,  ..., -0.3684, -2.2146, -0.5004],\n",
       "        [-1.3010,  1.4026, -0.8595,  ..., -0.3684,  0.1099, -0.5004],\n",
       "        ...,\n",
       "        [-0.0596,  1.5116, -0.9954,  ..., -0.3291,  0.5787, -0.4281],\n",
       "        [ 1.1818,  1.5116,  0.0916,  ..., -0.3684, -0.0072, -0.5004],\n",
       "        [-0.0596,  1.1844,  1.4503,  ..., -0.3684,  0.5721, -0.4281]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 256, 9, 9], but got 2-dimensional input of size [7200, 7] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-473a21fa78b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprimary_capsules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-655f42fceeb9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcapsule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcapsule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapsules\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(1)u:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-655f42fceeb9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcapsule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcapsule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapsules\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(1)u:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/anaconda3/envs/tensorflow1-x/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 256, 9, 9], but got 2-dimensional input of size [7200, 7] instead"
     ]
    }
   ],
   "source": [
    "primary_capsules.forward(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
